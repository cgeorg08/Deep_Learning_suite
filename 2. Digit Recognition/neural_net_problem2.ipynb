{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os \n",
    "import math\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# methods\n",
    "\n",
    "'''\n",
    "Map each letter to a number in the range 0-25 (26 letters in total).\n",
    "'''\n",
    "def letter2num(letter):\n",
    "    return int(ord(letter) - 65)\n",
    "\n",
    "'''\n",
    "Add +1 column for the bias. Not used in the last version.\n",
    "'''\n",
    "def add_bias_input(X):\n",
    "    bias_array = np.ones(len(X))\n",
    "    X = np.c_[X,bias_array]\n",
    "    return X\n",
    "\n",
    "'''\n",
    "Shuffle the data.\n",
    "'''\n",
    "def shuffle_data(X, y,features):\n",
    "    data_table = np.c_[X,y]\n",
    "    np.random.shuffle(data_table)\n",
    "    return data_table[:,:features], data_table[:,features]\n",
    "\n",
    "'''\n",
    "Split the data of a given table (input or output) into training and testing sets considering a fraction.\n",
    "'''\n",
    "def train_test_split(table,fraction):\n",
    "    train_size = len(table) * fraction\n",
    "    train_size = math.floor(train_size)\n",
    "    test_size = train_size + 1\n",
    "    return table[:test_size], table[test_size:]\n",
    "\n",
    "'''\n",
    "Create numpy array (either 1d or 2d) and fill it with NaNs.\n",
    "'''\n",
    "def create_array(dim1, dim2):\n",
    "    if dim2 != 0:   # 2d\n",
    "        arr=np.empty((dim1,dim2))\n",
    "    else:           # 1d\n",
    "        arr=np.empty(dim1)\n",
    "    arr.fill(np.NaN)\n",
    "    return arr\n",
    "\n",
    "'''\n",
    "Sigmoid activation function.\n",
    "'''\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "'''\n",
    "Apply the forward pass: find the values of the neurons using the dot product. \n",
    "'''\n",
    "def forward_phase(x_array, row):\n",
    "    for i in range(numHid1):\n",
    "        nodesHid1_values[i] = sigmoid(np.dot(x_array[row,:],in2hid_weights[:,i]) + hid1_biases[i])\n",
    "    for i in range(numHid2):\n",
    "        nodesHid2_values[i] = sigmoid(np.dot(nodesHid1_values[:],hid2hid_weights[:,i]) + hid2_biases[i])\n",
    "    for i in range(numOutput):\n",
    "        nodesOut_values[i] = sigmoid(np.dot(nodesHid2_values[:],hid2out_weights[:,i]) + out_biases[i])\n",
    "\n",
    "'''\n",
    "Return 1 if the current image is classified correctly.\n",
    "'''\n",
    "def calculate_success(target_values):\n",
    "    if target_values[np.argmax(nodesOut_values)] == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "'''\n",
    "Return \"cost\" of the current image to find Mean Square Error in the end of the epoch.\n",
    "'''\n",
    "def calculate_error(target_values):\n",
    "    return sum(np.square(nodesOut_values - target_values))\n",
    "\n",
    "def make_target_values(row, table):\n",
    "    arr=np.zeros(26)\n",
    "    arr[int(table[row])] = 1\n",
    "    return arr\n",
    "\n",
    "'''\n",
    "Update weights using the negative gradient to minimize the error.\n",
    "'''\n",
    "def backward_phase(row, target_values):\n",
    "    # step 1. find the partial derivatives (direction: backwards)\n",
    "    global nodesOut_deriv\n",
    "    nodesOut_deriv = nodesOut_values - target_values\n",
    "\n",
    "    for z in range(nodesHid2_deriv.shape[0]):\n",
    "        nodesHid2_deriv[z] = 0\n",
    "        for w in range(numOutput):\n",
    "            nodesHid2_deriv[z] = nodesHid2_deriv[z] + (hid2out_weights[z][w] * nodesOut_values[w] * (1-nodesOut_values[w]) * nodesOut_deriv[w])\n",
    "\n",
    "    for z in range(nodesHid1_deriv.shape[0]):\n",
    "        nodesHid1_deriv[z] = 0\n",
    "        for w in range(numHid2):\n",
    "            nodesHid1_deriv[z] = nodesHid1_deriv[z] + (hid2hid_weights[z][w] * nodesHid2_values[w] * (1-nodesHid2_values[w]) * nodesHid2_deriv[w])\n",
    "\n",
    "    # step 2. update weights and biases (direction: forward - but it does not matter since we have computed all the partial derivates until now)\n",
    "    for i in range(in2hid_weights.shape[0]):\n",
    "        for j in range(in2hid_weights.shape[1]):\n",
    "            tmp = in2hid_weights[i][j]\n",
    "            in2hid_weights[i][j] = in2hid_weights[i][j] - learning_rate * (X_train[row][i] * nodesHid1_values[j] * (1-nodesHid1_values[j]) * nodesHid1_deriv[j]) + momentum * (in2hid_weights[i][j] - in2hid_oldweights[i][j])\n",
    "            in2hid_oldweights[i][j] = tmp\n",
    "    for k in range(len(hid1_biases)):\n",
    "        tmp_b = hid1_biases[k]\n",
    "        hid1_biases[k] = hid1_biases[k] - learning_rate * (1 * nodesHid1_values[k] * (1-nodesHid1_values[k]) * nodesHid1_deriv[k]) + momentum * (hid1_biases[k] - hid1_oldbiases[k])\n",
    "        hid1_oldbiases[k] = tmp_b\n",
    "        \n",
    "    for i in range(hid2hid_weights.shape[0]):\n",
    "        for j in range(hid2hid_weights.shape[1]):\n",
    "            tmp = hid2hid_weights[i][j]\n",
    "            hid2hid_weights[i][j] = hid2hid_weights[i][j] - learning_rate * (nodesHid1_values[i] * nodesHid2_values[j] * (1-nodesHid2_values[j]) * nodesHid2_deriv[j]) + momentum * (hid2hid_weights[i][j] - hid2hid_oldweights[i][j])\n",
    "            hid2hid_oldweights[i][j] = tmp\n",
    "    for k in range(len(hid2_biases)):\n",
    "        tmp_b = hid2_biases[k]\n",
    "        hid2_biases[k] = hid2_biases[k] - learning_rate * (1 * nodesHid2_values[k] * (1-nodesHid2_values[k]) * nodesHid2_deriv[k]) + momentum * (hid2_biases[k] - hid2_oldbiases[k])\n",
    "        hid2_oldbiases[k] = tmp_b\n",
    "\n",
    "    for i in range(hid2out_weights.shape[0]):\n",
    "        for j in range(hid2out_weights.shape[1]):\n",
    "            tmp = hid2out_weights[i][j]\n",
    "            hid2out_weights[i][j] = hid2out_weights[i][j] - learning_rate * (nodesHid2_values[i] * nodesOut_values[j] * (1-nodesOut_values[j]) * nodesOut_deriv[j]) + momentum * (hid2out_weights[i][j] - hid2out_oldweights[i][j])\n",
    "            hid2out_oldweights[i][j] = tmp\n",
    "    for k in range(len(out_biases)):\n",
    "        tmp_b = out_biases[k]\n",
    "        out_biases[k] = out_biases[k] - learning_rate * (1 * nodesOut_values[k] * (1-nodesOut_values[k]) * nodesOut_deriv[k]) + momentum * (out_biases[k] - out_oldbiases[k])\n",
    "        out_oldbiases[k] = tmp_b\n",
    "\n",
    "'''\n",
    "Vizualize a monitored metric.\n",
    "'''\n",
    "def vizual(metric, label):\n",
    "    plt.plot(metric)\n",
    "\n",
    "    plt.xlabel(\"EPOCHS\")\n",
    "    plt.ylabel(label)\n",
    "    plt.title('{} over the EPOCHS'.format(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "\n",
    "# load the data\n",
    "file = open(os.path.dirname(os.path.abspath(\"__file__\")) + '/datasets/problem2_data.txt')\n",
    "for line in file.readlines():\n",
    "    vector = line.split(',')\n",
    "\n",
    "    y.append(letter2num(vector[0]))\n",
    "    current_list = list()\n",
    "    for i in range(1,len(vector)):\n",
    "        num = int(vector[i].replace('\\n', ''))\n",
    "        num = num / 15.0    # scaling\n",
    "        current_list.append(num)\n",
    "    X.append(current_list)\n",
    "file.close()\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# shuffle the data\n",
    "features = X.shape[1]\n",
    "X, y = shuffle_data(X, y,features)\n",
    "\n",
    "# split to train and test sets\n",
    "fraction = 0.7\n",
    "X_train, X_test = train_test_split(X,fraction)\n",
    "y_train, y_test = train_test_split(y,fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network constants\n",
    "\n",
    "numInput = features\n",
    "numHid1 = 60\n",
    "numHid2 = 50\n",
    "numOutput = 26 # letters of english alphabet\n",
    "\n",
    "learning_rate = 0.9\n",
    "epochs = 200\n",
    "momentum = 0.1\n",
    "\n",
    "# weights\n",
    "in2hid_weights = np.random.uniform(low=-1,high=1,size=(numInput,numHid1))\n",
    "hid2hid_weights = np.random.uniform(low=-1,high=1,size=(numHid1,numHid2))\n",
    "hid2out_weights = np.random.uniform(low=-1,high=1,size=(numHid2,numOutput))\n",
    "\n",
    "# biases\n",
    "hid1_biases = np.random.uniform(low=-1,high=1,size=numHid1)\n",
    "hid2_biases = np.random.uniform(low=-1,high=1,size=numHid2)\n",
    "out_biases = np.random.uniform(low=-1,high=1,size=numOutput)\n",
    "\n",
    "# old weights and biases\n",
    "in2hid_oldweights = np.copy(in2hid_weights)\n",
    "hid2hid_oldweights = np.copy(hid2hid_weights)\n",
    "hid2out_oldweights = np.copy(hid2out_weights) \n",
    "hid1_oldbiases = np.copy(hid1_biases)  \n",
    "hid2_oldbiases = np.copy(hid2_biases)\n",
    "out_oldbiases = np.copy(out_biases)  \n",
    "\n",
    "# values\n",
    "nodesHid1_values = create_array(dim1=numHid1,dim2=0)\n",
    "nodesHid2_values = create_array(dim1=numHid2,dim2=0)\n",
    "nodesOut_values = create_array(dim1=numOutput,dim2=0)\n",
    "\n",
    "# derivatives\n",
    "nodesHid1_deriv = create_array(dim1=numHid1,dim2=0)\n",
    "nodesHid2_deriv = create_array(dim1=numHid2,dim2=0)\n",
    "nodesOut_deriv = create_array(dim1=numOutput,dim2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_list = list()\n",
    "mse_list = list()\n",
    "counter = 0\n",
    "\n",
    "for ep in tqdm(range(epochs)):\n",
    "\n",
    "    epoch_success = 0\n",
    "    epoch_mse = 0\n",
    "\n",
    "    for row in range(X_train.shape[0]):\n",
    "\n",
    "        # forward phase\n",
    "        forward_phase(X_train, row)\n",
    "\n",
    "        # calculate success and error\n",
    "        target_values = make_target_values(row, y_train)\n",
    "        epoch_success += calculate_success(target_values)\n",
    "        epoch_mse += calculate_error(target_values)\n",
    "\n",
    "        # backward phase\n",
    "        backward_phase(row, target_values)\n",
    "        # counter += 1\n",
    "        # if counter % 4 == 0:\n",
    "        #     backward_phase(row, target_values)\n",
    "\n",
    "    epoch_mse = epoch_mse / X_train.shape[0]\n",
    "\n",
    "    success_list.append(epoch_success)\n",
    "    mse_list.append(epoch_mse)\n",
    "\n",
    "    print('EPOCH: {} | SUCCESS: {} - {}% | MSE: {}'.format(ep, epoch_success, epoch_success/X_train.shape[0], epoch_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizual(success_list,'success')\n",
    "vizual(mse_list,'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_success = 0\n",
    "test_mse = 0\n",
    "for row in range(X_test.shape[0]):\n",
    "\n",
    "    # forward phase\n",
    "    forward_phase(X_test, row, numLayers)\n",
    "\n",
    "    # calculate success and error\n",
    "    target_values = make_target_values(row, y_test)\n",
    "    test_success += calculate_success(target_values)\n",
    "    test_mse += calculate_error(target_values)\n",
    "\n",
    "test_mse = test_mse / X_test.shape[0]\n",
    "\n",
    "print('During testing: ')\n",
    "print('MSE : ', test_mse)\n",
    "print('Success: {} (out of {})'.format(test_success,X_test.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
